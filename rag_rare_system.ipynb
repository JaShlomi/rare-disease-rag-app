{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7921ab45-72c3-44de-addf-9b4f79e87fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "## üì¶ Configuration\n",
    "\n",
    "import os\n",
    "\n",
    "# OpenAI / LangChain\n",
    "# (temporarily hard-coded for local dev; remove this before sharing!)\n",
    "OPENAI_API_KEY = \"OPEN_AI_KEY"  \n",
    "OPENAI_MODEL   = \"gpt-4o-mini\"\n",
    "\n",
    "# NCBI / Entrez\n",
    "ENTREZ_EMAIL   = \"your_mail\"\n",
    "PUBMED_RETMAX  = 1000\n",
    "\n",
    "# OMIM MIM‚ÜíGene file\n",
    "MIM2GENE_PATH  = \"mim2gene.txt\"\n",
    "\n",
    "# Blazegraph SPARQL\n",
    "SPARQL_ENDPOINT = \"http://localhost:19999/blazegraph/sparql\"\n",
    "\n",
    "# FAISS index persistence\n",
    "FAISS_INDEX_PATH = \"faiss_index.pkl\"\n",
    "\n",
    "# Disease list\n",
    "DISEASE_LIST = [\n",
    "    \"Cystic fibrosis\",\n",
    "    \"Huntington disease\",\n",
    "    \"Duchenne muscular dystrophy\",\n",
    "    \"Spinal muscular atrophy\",\n",
    "    \"Hemophilia A\",\n",
    "    \"Hemophilia B\",\n",
    "    \"Gaucher disease\",\n",
    "    \"Fabry disease\",\n",
    "    \"Tay-Sachs disease\",\n",
    "    \"Phenylketonuria\",\n",
    "    \"Thalassemia\",\n",
    "    \"Sickle cell disease\",\n",
    "    \"Fragile X syndrome\",\n",
    "    \"Marfan syndrome\",\n",
    "    \"Dystonia\",\n",
    "    \"Wilson disease\",\n",
    "    \"Alpha-1 antitrypsin deficiency\",\n",
    "    \"Pompe disease\",\n",
    "    \"Neurofibromatosis type 1\",\n",
    "    \"Prader-Willi syndrome\"\n",
    "]\n",
    "\n",
    "# Quick sanity checks\n",
    "print(\"üîë OPENAI_API_KEY loaded:\", bool(OPENAI_API_KEY))\n",
    "print(\"‚úâÔ∏è  ENTREZ_EMAIL set to:\", ENTREZ_EMAIL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcad2587-aeb3-4cb7-bc5b-d4c3570cfbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "## üì• Imports & Client Setup\n",
    "\n",
    "import os\n",
    "import re\n",
    "from Bio import Entrez\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import streamlit as st\n",
    "\n",
    "# Use the new langchain-openai package for Chat & Embeddings\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Apply your config values\n",
    "Entrez.email = ENTREZ_EMAIL\n",
    "print(f\"‚úâÔ∏è  Entrez.email set to: {Entrez.email}\")\n",
    "\n",
    "# SPARQL client\n",
    "sparql = SPARQLWrapper(SPARQL_ENDPOINT)\n",
    "print(f\"üîó SPARQL endpoint set to: {SPARQL_ENDPOINT}\")\n",
    "\n",
    "# LLM client\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_API_KEY,\n",
    "    model_name=OPENAI_MODEL,\n",
    "    temperature=0\n",
    ")\n",
    "print(f\"ü§ñ OpenAI Chat model '{OPENAI_MODEL}' initialized.\")\n",
    "\n",
    "# Embeddings for FAISS\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "print(f\"üß¨ OpenAIEmbeddings ready.\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported and clients initialized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3809642-e50b-4b41-a650-3f1fa7c17862",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene2mim = {}\n",
    "with open(MIM2GENE_PATH) as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"#\"):\n",
    "            continue  # skip headers/comments\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) >= 4:\n",
    "            mim_number = parts[0]\n",
    "            gene_symbol = parts[3].strip()  # 4th column: \"Approved Gene Symbol (HGNC)\"\n",
    "            if gene_symbol:\n",
    "                gene2mim[gene_symbol.upper()] = mim_number\n",
    "\n",
    "print(f\"üîç Loaded {len(gene2mim)} gene symbols from '{MIM2GENE_PATH}'.\")\n",
    "\n",
    "import re\n",
    "gene_pattern = re.compile(r'\\b(' + '|'.join(map(re.escape, gene2mim.keys())) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "def detect_gene(text):\n",
    "    m = gene_pattern.search(text)\n",
    "    return m.group(1).upper() if m else None\n",
    "\n",
    "# Test gene detection\n",
    "test_q = \"What therapies target CFTR and DMD?\"\n",
    "found_gene = detect_gene(test_q)\n",
    "print(f\"üß¨ Test gene detection in: \\\"{test_q}\\\" ‚û°Ô∏è {found_gene}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632189a6-9acb-4249-b05d-639cfb9fea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "## üìö Load Disease Knowledge Graph Data\n",
    "\n",
    "import json\n",
    "\n",
    "KG_JSON_PATH = \"kg_definitional_data.json\"\n",
    "\n",
    "with open(KG_JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    kg_data = json.load(f)\n",
    "\n",
    "print(f\"üìñ Loaded {len(kg_data)} disease entries from '{KG_JSON_PATH}'.\")\n",
    "\n",
    "# Build a mapping from normalized disease name (\"comment\") to the entry\n",
    "disease_lookup = {}\n",
    "for entry in kg_data.values():\n",
    "    disease_name = entry.get(\"comment\")\n",
    "    if disease_name:\n",
    "        disease_lookup[disease_name.strip().lower()] = entry\n",
    "\n",
    "print(f\"üîé Indexed {len(disease_lookup)} diseases with valid names.\")\n",
    "\n",
    "# Test lookup: can we find cystic fibrosis?\n",
    "test_disease = \"Cystic fibrosis\"\n",
    "found = disease_lookup.get(test_disease.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e07556-199c-48ed-badc-b6a21f23edc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "## üõ†Ô∏è Build Retrieval Context for a User Question\n",
    "\n",
    "def get_rag_context(question):\n",
    "    # Normalize\n",
    "    q_lower = question.strip().lower()\n",
    "\n",
    "    # Disease context\n",
    "    disease_context = None\n",
    "    for disease_name in disease_lookup:\n",
    "        if disease_name in q_lower:\n",
    "            disease_context = disease_lookup[disease_name]\n",
    "            break\n",
    "\n",
    "    # Gene context\n",
    "    gene_symbol = detect_gene(question)\n",
    "    mim_context = None\n",
    "    if gene_symbol:\n",
    "        mim_id = gene2mim.get(gene_symbol)\n",
    "        if mim_id:\n",
    "            mim_context = {\"gene\": gene_symbol, \"mim\": mim_id}\n",
    "\n",
    "    # Build summary\n",
    "    context_summary = \"\"\n",
    "    if disease_context:\n",
    "        context_summary += f\"Disease: {disease_context.get('comment', 'N/A')}\\n\"\n",
    "        context_summary += f\"Orphanet code: {disease_context.get('label', 'N/A')}\\n\"\n",
    "    if mim_context:\n",
    "        context_summary += f\"Gene: {mim_context['gene']} (MIM: {mim_context['mim']})\\n\"\n",
    "\n",
    "    # If neither found, return None (or a flag)\n",
    "    if not (disease_context or mim_context):\n",
    "        return None, \"Sorry, your question is out of scope for the data I have.\"\n",
    "    else:\n",
    "        return {\n",
    "            \"disease\": disease_context,\n",
    "            \"gene\": mim_context,\n",
    "            \"summary\": context_summary\n",
    "        }, None\n",
    "\n",
    "# Example usage\n",
    "example_qs = [\n",
    "    \"What is known about cystic fibrosis?\",\n",
    "    \"Are there therapies for DMD?\",\n",
    "    \"Is SAPHO syndrome in the database?\",\n",
    "    \"What does the gene ALDH2 do?\",\n",
    "    \"Is Sickle cell disease included?\",\n",
    "    \"What is Prader-Willi syndrome?\",\n",
    "    \"Explain CFTR mutations.\",\n",
    "]\n",
    "\n",
    "for q in example_qs:\n",
    "    context, err = get_rag_context(q)\n",
    "    print(f\"\\nQ: {q}\")\n",
    "    if context:\n",
    "        print(\"Context summary:\")\n",
    "        print(context['summary'])\n",
    "    else:\n",
    "        print(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d22d0d-970a-4daf-9209-9ce7b22d6e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "## üì∞ Fetch PubMed Abstracts for Each Disease (up to 1000 per disease), with Logging & Saving\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from Bio import Entrez\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "Entrez.email = ENTREZ_EMAIL\n",
    "\n",
    "def fetch_abstracts(query, max_results=1000):\n",
    "    \"\"\"Fetches abstracts from PubMed for a given query.\"\"\"\n",
    "    try:\n",
    "        # 1. Get PMIDs\n",
    "        handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=max_results)\n",
    "        record = Entrez.read(handle)\n",
    "        pmids = record[\"IdList\"]\n",
    "        handle.close()\n",
    "\n",
    "        if not pmids:\n",
    "            print(f\"No PMIDs found for query: '{query}'\")\n",
    "            return [], 0\n",
    "\n",
    "        print(f\"Found {len(pmids)} PMIDs for query: '{query}'. Fetching abstracts...\")\n",
    "\n",
    "        # 2. Fetch abstracts in batches\n",
    "        abstracts_data = []\n",
    "        batch_size = 200\n",
    "        for i in range(0, len(pmids), batch_size):\n",
    "            batch_pmids = pmids[i: i + batch_size]\n",
    "            id_list = \",\".join(batch_pmids)\n",
    "            try:\n",
    "                with Entrez.efetch(db=\"pubmed\", id=id_list, retmode=\"xml\") as handle:\n",
    "                    records = Entrez.read(handle)\n",
    "                    for rec in records.get('PubmedArticle', []):\n",
    "                        pmid = str(rec.get(\"MedlineCitation\", {}).get(\"PMID\", \"N/A\"))\n",
    "                        title = rec.get(\"MedlineCitation\", {}).get(\"Article\", {}).get(\"ArticleTitle\", \"\")\n",
    "                        abstract_text = \"\"\n",
    "                        if rec.get(\"MedlineCitation\", {}).get(\"Article\", {}).get(\"Abstract\", {}).get(\"AbstractText\"):\n",
    "                            abstract_raw = rec[\"MedlineCitation\"][\"Article\"][\"Abstract\"][\"AbstractText\"]\n",
    "                            if isinstance(abstract_raw, list):\n",
    "                                abstract_text = \" \".join([str(t) for t in abstract_raw])\n",
    "                            else:\n",
    "                                abstract_text = str(abstract_raw)\n",
    "                        preprocessed_abstract = re.sub(r'\\s+', ' ', abstract_text.replace('\\n', ' ')).strip()\n",
    "                        if pmid != \"N/A\" and preprocessed_abstract:\n",
    "                            abstracts_data.append({\n",
    "                                \"pmid\": pmid,\n",
    "                                \"title\": str(title),\n",
    "                                \"abstract\": preprocessed_abstract\n",
    "                            })\n",
    "                time.sleep(0.34) # NCBI rate limit\n",
    "            except Exception as e:\n",
    "                print(f\"Error fetching batch of PMIDs {batch_pmids}: {e}\")\n",
    "                time.sleep(1)\n",
    "\n",
    "        print(f\"Successfully fetched {len(abstracts_data)} abstracts (out of {len(pmids)} PMIDs).\")\n",
    "        return abstracts_data, len(pmids)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during PubMed search: {e}\")\n",
    "        return [], 0\n",
    "\n",
    "# --- Main Retrieval for All Diseases ---\n",
    "output_dir = \"ncbi_abstracts\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "all_abstract_documents_for_faiss = []\n",
    "\n",
    "print(\"Starting abstract fetching and preprocessing for all diseases...\")\n",
    "for disease in DISEASE_LIST:\n",
    "    print(f\"\\nFetching abstracts for '{disease}'...\")\n",
    "    abstracts, n_pmids = fetch_abstracts(disease, max_results=1000)\n",
    "    file_name = os.path.join(output_dir, f\"{disease.lower().replace(' ', '_')}_abstracts.json\")\n",
    "    with open(file_name, 'w', encoding='utf-8') as f:\n",
    "        json.dump(abstracts, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"Summary for '{disease}':\")\n",
    "    print(f\"  PMIDs found: {n_pmids}\")\n",
    "    print(f\"  Abstracts saved: {len(abstracts)}\")\n",
    "    for item in abstracts:\n",
    "        all_abstract_documents_for_faiss.append(\n",
    "            Document(page_content=item['abstract'], metadata={\n",
    "                \"pmid\": item.get('pmid', 'N/A'),\n",
    "                \"title\": item.get('title', ''),\n",
    "                \"disease\": disease\n",
    "            })\n",
    "        )\n",
    "\n",
    "if not all_abstract_documents_for_faiss:\n",
    "    print(\"No documents found for FAISS after fetching. Please check queries and connection.\")\n",
    "\n",
    "print(f\"\\nTotal documents prepared for FAISS: {len(all_abstract_documents_for_faiss)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f86fd-fb83-4f55-b6a6-0e9017b7e119",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embedding_model_name = \"pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb\"  # Or any supported SentenceTransformer\n",
    "\n",
    "faiss_index_path = \"data/abstracts_faiss_index\"\n",
    "\n",
    "print(f\"\\nLoading HuggingFace model: {embedding_model_name} for FAISS index creation...\")\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "print(\"Embedding model loaded.\")\n",
    "\n",
    "print(f\"Creating LangChain FAISS vector store with {len(all_abstract_documents_for_faiss)} documents...\")\n",
    "vectorstore = FAISS.from_documents(all_abstract_documents_for_faiss, embeddings_model)\n",
    "print(\"LangChain FAISS vector store created.\")\n",
    "\n",
    "import os\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "print(f\"Saving FAISS index and metadata to {faiss_index_path} ...\")\n",
    "vectorstore.save_local(faiss_index_path)\n",
    "\n",
    "print(\"‚úÖ FAISS index and metadata saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d4e0be-89a8-4a7e-ac69-9b581adb4ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Load data, extractors, mappings ---\n",
    "# ... (Your current loading code exactly as is) ...\n",
    "# 1. Define your disease-to-ORDO URI mapping first\n",
    "\n",
    "from langchain.prompts import PromptTemplate \n",
    "\n",
    "disease_name_to_ordo_uri = {\n",
    "    \"Cystic Fibrosis\": \"http://www.orpha.net/ORDO/Orphanet_586\",\n",
    "    \"Huntington's Disease\": \"http://www.orpha.net/ORDO/Orphanet_418\",\n",
    "    \"Duchenne Muscular Dystrophy\": \"http://www.orpha.net/ORDO/Orphanet_683\",\n",
    "    \"Spinal Muscular Atrophy\": \"http://www.orpha.net/ORDO/Orphanet_84\",\n",
    "    \"Hemophilia A\": \"http://www.orpha.net/ORDO/Orphanet_448\",\n",
    "    \"Hemophilia B\": \"http://www.orpha.net/ORDO/Orphanet_447\",\n",
    "    \"Gaucher Disease\": \"http://www.orpha.net/ORDO/Orphanet_355\",\n",
    "    \"Pompe Disease\": \"http://www.orpha.net/ORDO/Orphanet_365\",\n",
    "    \"Neurofibromatosis type 1\": \"http://www.orpha.net/ORDO/Orphanet_636\",\n",
    "    \"Prader-Willi Syndrome\": \"http://www.orpha.net/ORDO/Orphanet_739\",\n",
    "    \"Angelman Syndrome\": \"http://www.orpha.net/ORDO/Orphanet_526\",\n",
    "    \"Rett Syndrome\": \"http://www.orpha.net/ORDO/Orphanet_802\",\n",
    "    \"Fragile X Syndrome\": \"http://www.orpha.net/ORDO/Orphanet_908\",\n",
    "    \"Phenylketonuria\": \"http://www.orpha.net/ORDO/Orphanet_716\",\n",
    "    \"Alpha-1 Antitrypsin Deficiency\": \"http://www.orpha.net/ORDO/Orphanet_60\",\n",
    "    \"Marfan Syndrome\": \"http://www.orpha.net/ORDO/Orphanet_284\",\n",
    "    \"Ehlers-Danlos Syndrome, Hypermobile Type\": \"http://www.orpha.net/ORDO/Orphanet_98253\",\n",
    "    \"Sickle Cell Anemia\": \"http://www.orpha.net/ORDO/Orphanet_232\",\n",
    "    \"Thalassemia Major\": \"http://www.orpha.net/ORDO/Orphanet_821\",\n",
    "    \"Crigler-Najjar Syndrome Type 1\": \"http://www.orpha.net/ORDO/Orphanet_792\"\n",
    "}\n",
    "\n",
    "# 2. Now you can safely use its keys:\n",
    "all_supported_diseases = set(disease_name_to_ordo_uri.keys())\n",
    "\n",
    "# (Optional) Helper function, if you want\n",
    "def is_supported_disease(query):\n",
    "    disease = extract_disease_from_query(query)\n",
    "    return disease in all_supported_diseases if disease else False\n",
    "\n",
    "\n",
    "all_supported_diseases = set(disease_name_to_ordo_uri.keys())\n",
    "\n",
    "def is_supported_disease(query):\n",
    "    disease = extract_disease_from_query(query)\n",
    "    return disease in all_supported_diseases\n",
    "\n",
    "# --- 2. Enhanced Prompt ---\n",
    "disease_list = \", \".join(all_supported_diseases)\n",
    "template = (\n",
    "    \"You are a helpful assistant specialized in rare diseases. \"\n",
    "    \"You only answer questions about the following diseases: \" + disease_list + \". \"\n",
    "    \"If asked about anything else, reply: \"\n",
    "    \"'Sorry, I can only answer questions about these 20 rare diseases: \" + disease_list + \".'\\n\\n\"\n",
    "    \"Provide a comprehensive, detailed answer, summarizing all relevant aspects from the context below. \"\n",
    "    \"Where appropriate, cite supporting PubMed IDs (PMIDs) or gene symbols. \"\n",
    "    \"Use headings, bullet points, and structured sections where helpful.\\n\\n\"\n",
    "    \"Context from Scientific Abstracts:\\n\"\n",
    "    \"{context}\\n\\n\"\n",
    "    \"Structured Knowledge Graph Context (from Blazegraph):\\n\"\n",
    "    \"{blazegraph_context}\\n\\n\"\n",
    "    \"Gene and MIM Context (from mim2gene.txt):\\n\"\n",
    "    \"{mim_gene_context}\\n\\n\"\n",
    "    \"Question: {question}\\n\"\n",
    "    \"Answer:\\n\"\n",
    ")\n",
    "RAG_PROMPT_CUSTOM = PromptTemplate.from_template(template)\n",
    "print(\"Load data, extractors, mappings - completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725dc2a4-9232-44e5-b928-6f71c1cd4cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "\n",
    "# --- Load KG (ORDO) definitional data ---\n",
    "kg_data_file = \"kg_definitional_data.json\"\n",
    "with open(kg_data_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    kg_definitional_data_loaded = json.load(f)\n",
    "print(f\"Loaded {len(kg_definitional_data_loaded)} definitional entries from {kg_data_file}.\")\n",
    "\n",
    "# --- Load mim2gene.txt as dictionary (you should already have mim_gene_data loaded) ---\n",
    "mim_gene_data = {}\n",
    "with open(\"mim2gene.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"#\"):\n",
    "            continue\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) >= 4:\n",
    "            mim_number = parts[0]\n",
    "            mim_entry_type = parts[1]\n",
    "            entrez_gene_id = parts[2] if parts[2] else None\n",
    "            approved_gene_symbol = parts[3] if parts[3] else None\n",
    "            if approved_gene_symbol:\n",
    "                mim_gene_data[approved_gene_symbol.upper()] = {\n",
    "                    \"mim_number\": mim_number,\n",
    "                    \"mim_entry_type\": mim_entry_type,\n",
    "                    \"entrez_gene_id\": entrez_gene_id,\n",
    "                    \"approved_gene_symbol\": approved_gene_symbol\n",
    "                }\n",
    "            if entrez_gene_id and entrez_gene_id not in mim_gene_data:\n",
    "                mim_gene_data[entrez_gene_id] = {\n",
    "                    \"mim_number\": mim_number,\n",
    "                    \"mim_entry_type\": mim_entry_type,\n",
    "                    \"entrez_gene_id\": entrez_gene_id,\n",
    "                    \"approved_gene_symbol\": approved_gene_symbol\n",
    "                }\n",
    "print(f\"Loaded {len(mim_gene_data)} entries from mim2gene.txt.\")\n",
    "\n",
    "# --- Load your FAISS vectorstore ---\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "embedding_model_name = \"all-MiniLM-L6-v2\"\n",
    "faiss_index_path = \"data/abstracts_faiss_index\"\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "vectorstore = FAISS.load_local(\n",
    "    faiss_index_path,\n",
    "    embeddings_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# --- Supported Disease Restriction ---\n",
    "disease_name_to_ordo_uri = {\n",
    "    \"Cystic Fibrosis\": \"http://www.orpha.net/ORDO/Orphanet_586\",\n",
    "    \"Huntington's Disease\": \"http://www.orpha.net/ORDO/Orphanet_418\",\n",
    "    \"Duchenne Muscular Dystrophy\": \"http://www.orpha.net/ORDO/Orphanet_683\",\n",
    "    \"Spinal Muscular Atrophy\": \"http://www.orpha.net/ORDO/Orphanet_84\",\n",
    "    \"Hemophilia A\": \"http://www.orpha.net/ORDO/Orphanet_448\",\n",
    "    \"Hemophilia B\": \"http://www.orpha.net/ORDO/Orphanet_447\",\n",
    "    \"Gaucher Disease\": \"http://www.orpha.net/ORDO/Orphanet_355\",\n",
    "    \"Pompe Disease\": \"http://www.orpha.net/ORDO/Orphanet_365\",\n",
    "    \"Neurofibromatosis type 1\": \"http://www.orpha.net/ORDO/Orphanet_636\",\n",
    "    \"Prader-Willi Syndrome\": \"http://www.orpha.net/ORDO/Orphanet_739\",\n",
    "    \"Angelman Syndrome\": \"http://www.orpha.net/ORDO/Orphanet_526\",\n",
    "    \"Rett Syndrome\": \"http://www.orpha.net/ORDO/Orphanet_802\",\n",
    "    \"Fragile X Syndrome\": \"http://www.orpha.net/ORDO/Orphanet_908\",\n",
    "    \"Phenylketonuria\": \"http://www.orpha.net/ORDO/Orphanet_716\",\n",
    "    \"Alpha-1 Antitrypsin Deficiency\": \"http://www.orpha.net/ORDO/Orphanet_60\",\n",
    "    \"Marfan Syndrome\": \"http://www.orpha.net/ORDO/Orphanet_284\",\n",
    "    \"Ehlers-Danlos Syndrome, Hypermobile Type\": \"http://www.orpha.net/ORDO/Orphanet_98253\",\n",
    "    \"Sickle Cell Anemia\": \"http://www.orpha.net/ORDO/Orphanet_232\",\n",
    "    \"Thalassemia Major\": \"http://www.orpha.net/ORDO/Orphanet_821\",\n",
    "    \"Crigler-Najjar Syndrome Type 1\": \"http://www.orpha.net/ORDO/Orphanet_792\"\n",
    "}\n",
    "all_supported_diseases = set(disease_name_to_ordo_uri.keys())\n",
    "disease_list = \", \".join(all_supported_diseases)\n",
    "\n",
    "def extract_disease_from_query(query):\n",
    "    \"\"\"Detect if the query is about a supported disease; return standard name or None.\"\"\"\n",
    "    query_lower = query.lower()\n",
    "    if \"cystic fibrosis\" in query_lower:\n",
    "        return \"Cystic Fibrosis\"\n",
    "    if \"huntington\" in query_lower:\n",
    "        return \"Huntington's Disease\"\n",
    "    if \"duchenne\" in query_lower:\n",
    "        return \"Duchenne Muscular Dystrophy\"\n",
    "    if \"spinal muscular atrophy\" in query_lower or \"sma\" in query_lower:\n",
    "        return \"Spinal Muscular Atrophy\"\n",
    "    if \"hemophilia a\" in query_lower:\n",
    "        return \"Hemophilia A\"\n",
    "    if \"hemophilia b\" in query_lower:\n",
    "        return \"Hemophilia B\"\n",
    "    if \"gaucher\" in query_lower:\n",
    "        return \"Gaucher Disease\"\n",
    "    if \"pompe\" in query_lower:\n",
    "        return \"Pompe Disease\"\n",
    "    if \"neurofibromatosis\" in query_lower or \"nf1\" in query_lower:\n",
    "        return \"Neurofibromatosis type 1\"\n",
    "    if \"prader-willi\" in query_lower:\n",
    "        return \"Prader-Willi Syndrome\"\n",
    "    if \"angelman\" in query_lower:\n",
    "        return \"Angelman Syndrome\"\n",
    "    if \"rett\" in query_lower:\n",
    "        return \"Rett Syndrome\"\n",
    "    if \"fragile x\" in query_lower or \"fxs\" in query_lower:\n",
    "        return \"Fragile X Syndrome\"\n",
    "    if \"phenylketonuria\" in query_lower or \"pku\" in query_lower:\n",
    "        return \"Phenylketonuria\"\n",
    "    if \"alpha-1 antitrypsin\" in query_lower or \"aatd\" in query_lower:\n",
    "        return \"Alpha-1 Antitrypsin Deficiency\"\n",
    "    if \"marfan\" in query_lower:\n",
    "        return \"Marfan Syndrome\"\n",
    "    if \"ehlers-danlos\" in query_lower or \"eds\" in query_lower:\n",
    "        return \"Ehlers-Danlos Syndrome, Hypermobile Type\"\n",
    "    if \"sickle cell\" in query_lower:\n",
    "        return \"Sickle Cell Anemia\"\n",
    "    if \"thalassemia major\" in query_lower:\n",
    "        return \"Thalassemia Major\"\n",
    "    if \"crigler-najjar\" in query_lower:\n",
    "        return \"Crigler-Najjar Syndrome Type 1\"\n",
    "    return None\n",
    "\n",
    "def is_supported_disease(query):\n",
    "    disease = extract_disease_from_query(query)\n",
    "    return disease in all_supported_diseases\n",
    "\n",
    "# --- Gene or MIM extractor ---\n",
    "def extract_gene_or_mim_from_query(query):\n",
    "    import re\n",
    "    potential_matches = []\n",
    "    for mim_match in re.finditer(r'\\b\\d{6}\\b', query):\n",
    "        potential_mim = mim_match.group(0)\n",
    "        potential_matches.append(potential_mim)\n",
    "    for gene_match in re.finditer(r'\\b[A-Z][A-Z0-9]{2,}\\b', query, re.IGNORECASE):\n",
    "        potential_symbol = gene_match.group(0).upper()\n",
    "        potential_matches.append(potential_symbol)\n",
    "    for match in potential_matches:\n",
    "        if match in mim_gene_data:\n",
    "            return match\n",
    "    for match in potential_matches:\n",
    "        if match.isdigit():\n",
    "            for key, value in mim_gene_data.items():\n",
    "                if value.get(\"mim_number\") == match:\n",
    "                    return match\n",
    "    return None\n",
    "\n",
    "# ------- Improved Prompt -------\n",
    "template = (\n",
    "    \"You are a helpful assistant specialized in rare diseases. \"\n",
    "    \"You only answer questions about the following diseases: \" + disease_list + \". \"\n",
    "    \"If asked about anything else, reply: \"\n",
    "    \"'Sorry, I can only answer questions about these 20 rare diseases: \" + disease_list + \".'\\n\\n\"\n",
    "    \"For supported questions:\\n\"\n",
    "    \"- Start with a 2‚Äì3 sentence summary (TL;DR).\\n\"\n",
    "    \"- Follow with a comprehensive, structured answer using clear headings, bullet points, and explanations.\\n\"\n",
    "    \"- Where possible, reference supporting PubMed IDs (PMIDs) or gene symbols **inline** (e.g., '...as shown in (PMID: 123456)').\\n\"\n",
    "    \"- Conclude with an 'Evidence' section listing the PMIDs and titles of the most relevant scientific articles.\\n\"\n",
    "    \"- If you do not know the answer from the provided context, say so and do not make up information.\\n\\n\"\n",
    "    \"Context from Scientific Abstracts:\\n\"\n",
    "    \"{context}\\n\\n\"\n",
    "    \"Structured Knowledge Graph Context (from Blazegraph):\\n\"\n",
    "    \"{blazegraph_context}\\n\\n\"\n",
    "    \"Gene and MIM Context (from mim2gene.txt):\\n\"\n",
    "    \"{mim_gene_context}\\n\\n\"\n",
    "    \"Question: {question}\\n\"\n",
    "    \"Answer:\\n\"\n",
    ")\n",
    "\n",
    "RAG_PROMPT_CUSTOM = PromptTemplate.from_template(template)\n",
    "\n",
    "# ------- Combined Retrieval -------\n",
    "def get_combined_retrieval_context(input_dict):\n",
    "    query = input_dict[\"query\"]\n",
    "    abstract_docs = vectorstore.as_retriever(search_kwargs={\"k\": 10}).invoke(query)\n",
    "    abstract_context = \"\\n\\n\".join([doc.page_content for doc in abstract_docs])\n",
    "\n",
    "    disease_name_extracted = extract_disease_from_query(query)\n",
    "    kg_data_str = \"No specific rare disease definitional data found in knowledge graph.\"\n",
    "    if disease_name_extracted:\n",
    "        ordo_uri = disease_name_to_ordo_uri.get(disease_name_extracted)\n",
    "        if ordo_uri:\n",
    "            kg_data = kg_definitional_data_loaded.get(ordo_uri)\n",
    "            if kg_data:\n",
    "                disease_name_for_prompt = kg_data.get('comment', kg_data.get('label', 'N/A'))\n",
    "                kg_data_str = (\n",
    "                    f\"Disease Name: {disease_name_for_prompt}\\n\"\n",
    "                    f\"URI: {kg_data.get('uri', 'N/A')}\\n\"\n",
    "                    f\"Description: {kg_data.get('comment', 'N/A')}\\n\"\n",
    "                    f\"DB Xref: {kg_data.get('dbXref', 'N/A')}\\n\"\n",
    "                    f\"Parent Class: {kg_data.get('parentLabel', 'N/A')}\"\n",
    "                )\n",
    "    mim_gene_context_str = \"No specific gene or MIM data found in mim2gene.txt.\"\n",
    "    extracted_identifier = extract_gene_or_mim_from_query(query)\n",
    "    if extracted_identifier:\n",
    "        gene_info = mim_gene_data.get(extracted_identifier)\n",
    "        if not gene_info and extracted_identifier.isdigit():\n",
    "            for key, value in mim_gene_data.items():\n",
    "                if value.get(\"mim_number\") == extracted_identifier:\n",
    "                    gene_info = value\n",
    "                    break\n",
    "        if gene_info:\n",
    "            mim_gene_context_str = (\n",
    "                \"MIM Number: \" + gene_info.get('mim_number', 'N/A') + \"\\n\" +\n",
    "                \"MIM Entry Type: \" + gene_info.get('mim_entry_type', 'N/A') + \"\\n\" +\n",
    "                \"Entrez Gene ID: \" + gene_info.get('entrez_gene_id', 'N/A') + \"\\n\" +\n",
    "                \"Approved Gene Symbol: \" + gene_info.get('approved_gene_symbol', 'N/A')\n",
    "            )\n",
    "    return {\n",
    "        \"context\": abstract_context,\n",
    "        \"blazegraph_context\": kg_data_str,\n",
    "        \"mim_gene_context\": mim_gene_context_str,\n",
    "        \"question\": query\n",
    "    }\n",
    "\n",
    "# ------- Initialize LLM -------\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.2,\n",
    "    openai_api_key=\"OPEN_AI_KEY\"\n",
    ")\n",
    "\n",
    "rag_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        retrieved_data=lambda x: get_combined_retrieval_context(x)\n",
    "    )\n",
    "    | {\n",
    "        \"context\": lambda x: x[\"retrieved_data\"][\"context\"],\n",
    "        \"blazegraph_context\": lambda x: x[\"retrieved_data\"][\"blazegraph_context\"],\n",
    "        \"mim_gene_context\": lambda x: x[\"retrieved_data\"][\"mim_gene_context\"],\n",
    "        \"question\": lambda x: x[\"query\"]\n",
    "    }\n",
    "    | RAG_PROMPT_CUSTOM\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ------- Query and Evidence -------\n",
    "query = \"What are the recent review findings on therapeutic approaches for cystic fibrosis lung disease and its associated genes like CFTR?\"\n",
    "\n",
    "if not is_supported_disease(query):\n",
    "    print(f\"Sorry, I can only answer questions about these 20 rare diseases: {disease_list}.\")\n",
    "else:\n",
    "    # Retrieve evidence for this query (same as before)\n",
    "    k = 10  # Or whatever you want\n",
    "    abstract_docs = vectorstore.as_retriever(search_kwargs={\"k\": k}).invoke(query)\n",
    "    response = rag_chain.invoke({\"query\": query})\n",
    "\n",
    "    # --- AUTO-APPEND SOURCES ---\n",
    "    pmid_list = []\n",
    "    for doc in abstract_docs:\n",
    "        pmid = doc.metadata.get(\"pmid\", \"N/A\")\n",
    "        title = doc.metadata.get(\"title\", \"\")\n",
    "        if pmid != \"N/A\":\n",
    "            pmid_list.append(f\"- PMID: {pmid}, Title: {title[:100]}...\")\n",
    "\n",
    "    if pmid_list:\n",
    "        evidence_section = \"\\n\\n--- Evidence Sources (auto-appended) ---\\n\" + \"\\n\".join(pmid_list)\n",
    "    else:\n",
    "        evidence_section = \"\\n\\n--- Evidence Sources: None found. ---\"\n",
    "\n",
    "    print(\"\\n--- LLM Answer ---\\n\")\n",
    "    print(response + evidence_section)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df9c78-d053-47ba-89d8-b872def08479",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"What are the current clinical challenges and emerging treatments for Spinal Muscular Atrophy (SMA)?\",\n",
    "    \"How does alpha-1 antitrypsin deficiency impact liver and lung health, and what gene therapies are under investigation?\",\n",
    "    \"Summarize the latest advances in diagnosing Gaucher Disease, including the role of GBA gene mutations.\"\n",
    "]\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nRunning query: {query}\")\n",
    "    if not is_supported_disease(query):\n",
    "        answer = f\"Sorry, I can only answer questions about these 20 rare diseases: {list(disease_name_to_ordo_uri.keys())}.\"\n",
    "        sources = \"\"\n",
    "    else:\n",
    "        k = 10\n",
    "        abstract_docs = vectorstore.as_retriever(search_kwargs={\"k\": k}).invoke(query)\n",
    "        response = rag_chain.invoke({\"query\": query})\n",
    "\n",
    "        pmid_list = []\n",
    "        for doc in abstract_docs:\n",
    "            pmid = doc.metadata.get(\"pmid\", \"N/A\")\n",
    "            title = doc.metadata.get(\"title\", \"\")\n",
    "            if pmid != \"N/A\":\n",
    "                pmid_list.append(f\"- PMID: {pmid}, Title: {title[:100]}...\")\n",
    "\n",
    "        sources = \"\\n--- Evidence Sources (auto-appended) ---\\n\" + \"\\n\".join(pmid_list) if pmid_list else \"\\n--- Evidence Sources: None found. ---\"\n",
    "        answer = response\n",
    "\n",
    "    results.append({\"query\": query, \"answer\": answer + sources})\n",
    "    print(\"Done.\")\n",
    "\n",
    "# Write results to a text file (simple line-by-line, or use json for structure)\n",
    "import json\n",
    "with open(\"rag_batch_results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"All results written to rag_batch_results.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866cab21-08ce-4d70-9d9b-27040d0f7ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
